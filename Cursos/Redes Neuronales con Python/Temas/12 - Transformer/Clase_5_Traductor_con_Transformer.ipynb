{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvrNWj-x_u4E"
      },
      "source": [
        "# Traducción de inglés a español con un Transformer de secuencia a secuencia\n",
        "## English-to-Spanish translation with a sequence-to-sequence Transformer\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2021/05/26<br>\n",
        "**Last modified:** 2023/02/25<br>\n",
        "**Description:** Implementing a sequence-to-sequence Transformer and training it on a machine translation task.\n",
        "\n",
        "**Revised and updated by:** Edgardo Bonzi   \n",
        "**Updated on:** 2023/11/25"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción\n",
        "\n",
        "En este ejemplo, construiremos un modelo Transformer de secuencia a secuencia, que entrenaremos en una tarea de traducción automática del inglés al español.\n",
        "\n",
        "Aprenderás cómo:\n",
        "\n",
        "- Vectorizar el texto usando la capa Keras TextVectorization.\n",
        "- Implementar una capa TransformerEncoder, una capa TransformerDecoder y una capa PositionalEmbedding.\n",
        "- Preparar datos para entrenar un modelo secuencia a secuencia.\n",
        "- Utilizar el modelo entrenado para generar traducciones de oraciones de entrada nunca antes vistas (inferencia secuencia a secuencia).\n",
        "\n",
        "El código que se presenta aquí está adaptado del libro [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n",
        "(chapter 11: Deep learning for text).  \n",
        "El presente ejemplo es bastante básico, por lo que para obtener explicaciones detalladas de cómo funciona cada componente, así como la teoría detrás de Transformers, se recomienda leer el libro."
      ],
      "metadata": {
        "id": "vUVsuCzSLOXN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuYqekSX_u4J"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zVxjg0c2_u4K"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Estas sentencias se utilizan para configurar la variable de entorno \"KERAS_BACKEND\"\n",
        "en el entorno de ejecución de Python.\n",
        "---------------------------------------------------------------------------------\n",
        "Esta línea importa el módulo os, que permite interactuar con el sistema operativo\n",
        "utilizando Python.\n",
        "\"\"\"\n",
        "import os\n",
        "\"\"\"\n",
        "---------------------------------------------------------------------------------\n",
        "Esta línea establece una variable de entorno llamada \"KERAS_BACKEND\" y la configura\n",
        "con el valor \"tensorflow\".\n",
        "\"\"\"\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\"\"\"\n",
        "---------------------------------------------------------------------------------\n",
        "En el contexto de Keras, el parámetro \"KERAS_BACKEND\" se utiliza para especificar\n",
        "qué backend se debe utilizar para las operaciones de Keras. Keras es una biblioteca\n",
        "de alto nivel para la creación de redes neuronales, y puede funcionar con varios\n",
        "backends, como TensorFlow, Theano o CNTK.\n",
        "\n",
        "En este caso particular, se configura \"tensorflow\" como el backend de Keras.\n",
        "Esto significa que las operaciones de Keras se ejecutarán utilizando TensorFlow\n",
        "como motor subyacente para realizar los cálculos.\n",
        "\n",
        "Esto es útil cuando se quiere asegurar que Keras utilice específicamente TensorFlow\n",
        "como su backend para las operaciones de aprendizaje profundo en lugar de otros\n",
        "motores o backends disponibles.\n",
        "\"\"\"\n",
        "## import os\n",
        "## os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías de Python utilizadas\n",
        "\n",
        "1. **`pathlib`:** Esta librería proporciona clases para interactuar con rutas de sistema de archivos de una manera más orientada a objetos. Permite manipular rutas de manera más eficiente y consistente. Algunas de las operaciones comunes incluyen la navegación entre directorios, la comprobación de la existencia de archivos o directorios, la obtención de información sobre rutas y nombres de archivo, entre otras. Es parte de la biblioteca estándar de Python y es útil para trabajar con rutas de archivos y directorios.\n",
        "\n",
        "2. **`random`:** La librería `random` proporciona funciones para trabajar con números aleatorios. Puede generar números aleatorios enteros, de punto flotante, mezclar secuencias, elegir elementos aleatorios de una secuencia y más. Es útil para tareas que requieren aleatoriedad, como la selección aleatoria, la generación de datos de prueba o la mezcla de elementos.\n",
        "\n",
        "3. **`string`:** La librería `string` proporciona constantes y funciones útiles para trabajar con cadenas de texto. Contiene constantes predefinidas para letras mayúsculas y minúsculas, dígitos, puntuación y otros grupos de caracteres. También ofrece funciones para formatear, manipular y trabajar con cadenas de texto, como la conversión entre mayúsculas y minúsculas, la eliminación de espacios en blanco, entre otros.\n",
        "\n",
        "4. **`re`:** La librería `re` proporciona operaciones de expresiones regulares en Python. Permite trabajar con patrones de texto para buscar, extraer y manipular cadenas de texto basadas en reglas específicas definidas por expresiones regulares. Ofrece funciones como `search`, `match`, `findall`, `sub`, entre otras, para realizar operaciones avanzadas de búsqueda y manipulación de cadenas basadas en patrones específicos. Las expresiones regulares son muy potentes y útiles para realizar operaciones complejas de coincidencia y manipulación de texto."
      ],
      "metadata": {
        "id": "nRvWfHkucFAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import TextVectorization\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "vfdv3nx_hVbk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eNUOFrQ_u4L"
      },
      "source": [
        "## Descargando los datos\n",
        "\n",
        "Trabajaremos con un conjunto de datos de traducción del inglés al español proporcionado por [Anki](https://www.manythings.org/anki/).  \n",
        "\n",
        "Vamos a descargarlo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5dFD2uFE_u4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2398def-a22c-42f8-8d2b-0871bda26653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2638744/2638744 [==============================] - 0s 0us/step\n",
            "CPU times: user 76.1 ms, sys: 15.8 ms, total: 91.9 ms\n",
            "Wall time: 207 ms\n"
          ]
        }
      ],
      "source": [
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HacLuLVM_u4N"
      },
      "source": [
        "## Analizando los datos\n",
        "\n",
        "Cada línea contiene una oración en inglés y su correspondiente oración en español.  \n",
        "La oración en inglés es la *secuencia fuente* y la oración en español es la *secuencia objetivo*.  \n",
        "En esta celda, anteponemos el token `\"[start]\"` y agregamos el token `\"[end]\"` a la oración en español."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Gt9UvozX_u4N"
      },
      "outputs": [],
      "source": [
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL1_fO_N_u4N"
      },
      "source": [
        "Así es como se ven nuestros pares de oraciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mBwaHdH6_u4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd89650-664e-44e8-cf01-434d4cabbbe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('I like to dance with Mary.', '[start] Me gusta bailar con Mary. [end]')\n",
            "('Life is enjoyable.', '[start] La vida es divertida. [end]')\n",
            "(\"Tom couldn't find what he was looking for.\", '[start] Tom no pudo encontrar lo que estaba buscando. [end]')\n",
            "('The meeting took place yesterday.', '[start] La reunión tuvo lugar ayer. [end]')\n",
            "('The pond is 3 meters deep.', '[start] La laguna tiene 3 metros de profundidad. [end]')\n"
          ]
        }
      ],
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "689dW2Ur_u4O"
      },
      "source": [
        "Ahora, dividamos los pares de oraciones en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BmBfpj8m_u4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4910930c-f040-4bb4-fcc5-a8fdf7351455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "\n",
        "# primeros 70 %\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "# del 70 % al 85 %\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "# últimos 15 %\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorizando los datos del texto\n",
        "\n",
        "Usaremos dos instancias de la capa `TextVectorization` para vectorizar los datos de texto (una para inglés y otra para español), es decir, convertir las cadenas originales en secuencias de números enteros donde cada número entero representa el índice de una palabra en un vocabulario.\n",
        "\n",
        "La capa en inglés utilizará la estandarización de cadenas predeterminada (eliminar caracteres de puntuación) y esquema de división (dividido en espacios en blanco), mientras que la capa española usará una estandarización personalizada, donde agregamos el carácter\n",
        "`\"¿\"` al conjunto de caracteres de puntuación que se eliminarán.\n"
      ],
      "metadata": {
        "id": "0tz1VbMJZC1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wdPy9xzA_u4P"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "La línea strip_chars = strip_chars.replace(\"[\", \"\") utiliza el método\n",
        "replace() para modificar una cadena llamada strip_chars. Así es cómo funciona:\n",
        "\n",
        "    strip_chars.replace(\"[\", \"\"): Esta línea invoca el método replace() en la\n",
        "    cadena strip_chars. La función replace() busca todos los caracteres que\n",
        "    coinciden con el primer argumento (en este caso, el carácter \"[\"), y los\n",
        "    reemplaza con el segundo argumento (en este caso, una cadena vacía \"\", lo\n",
        "    que significa eliminar esos caracteres).\n",
        "\n",
        "    strip_chars = strip_chars.replace(\"[\", \"\"): La línea completa asigna el\n",
        "    resultado de la operación replace() de nuevo a la variable strip_chars.\n",
        "\n",
        "    Esto significa que la cadena original strip_chars se modifica y reemplaza\n",
        "    todas las ocurrencias del carácter \"[\" por una cadena vacía \"\" en sí misma.\n",
        "    Similarmente sucede con el carácter \"]\".\n",
        "\"\"\"\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\"\"\"\n",
        "La siguiente parte del código esta relacionada con la vectorización de texto\n",
        "utilizando la clase TextVectorization de TensorFlow.\n",
        "\n",
        "Ésta es la explicación de los parámetros utilizados:\n",
        "\n",
        "    max_tokens=vocab_size:\n",
        "    Este parámetro define la cantidad máxima de tokens únicos que se utilizarán\n",
        "    en la vectorización. vocab_size representa el tamaño máximo del vocabulario,\n",
        "    es decir, la cantidad máxima de palabras diferentes permitidas.\n",
        "\n",
        "    output_mode=\"int\":\n",
        "    Este parámetro especifica el modo de salida de la vectorización.\n",
        "    En este caso, se configura para que la salida sea una representación entera de\n",
        "    las palabras/tokenes.\n",
        "\n",
        "    output_sequence_length=sequence_length:\n",
        "    Aquí se establece la longitud máxima de las secuencias de salida.\n",
        "    'sequence_length' indica la longitud máxima que tendrá cada secuencia\n",
        "    después de la vectorización.\n",
        "\n",
        "En síntesis, esta configuración de 'TextVectorization' indica que se va a realizar\n",
        "una vectorización de texto con un límite de tokens, se generarán representaciones\n",
        "enteras para los tokens y se limitará la longitud de las secuencias de salida a un\n",
        "tamaño específico (sequence_length).\n",
        "\n",
        "\"\"\"\n",
        "# Para el texto en inglés\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "    La siguiente sentencia es similar a la anterior, pero se le agrega el uso de la\n",
        "      función definida \"custom_standardization\" (standardize=custom_standardization)\n",
        "\"\"\"\n",
        "# Para el texto en español\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "    train_eng_texts = [pair[0] for pair in train_pairs]:\n",
        "    Esta línea crea una lista 'train_eng_texts' que contiene el primer elemento\n",
        "    de cada par en 'train_pairs'.\n",
        "    'train_pairs' es la lista de pares donde el primer elemento de cada par es un texto en inglés.\n",
        "\n",
        "    Para realizar esta actividad, usamos un loop for 'condensado'\n",
        "\"\"\"\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "\n",
        "\"\"\"\n",
        "    eng_vectorization.adapt(train_eng_texts):\n",
        "    La llamada al método adapt() ajusta el componente eng_vectorization\n",
        "    basándose en los textos de entrenamiento en inglés proporcionados en\n",
        "    'train_eng_texts'.\n",
        "    Lo que esto hace es analizar los textos de entrenamiento para construir el\n",
        "    vocabulario, tokenizar y preprocesar el texto según los parámetros\n",
        "    previamente configurados en eng_vectorization.\n",
        "    La adaptación permite que el componente aprenda del corpus de entrenamiento\n",
        "    y ajuste su comportamiento (como el vocabulario y las transformaciones aplicadas)\n",
        "    para que coincida mejor con los datos reales.\n",
        "\"\"\"\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, formatearemos nuestros conjuntos de datos.\n",
        "\n",
        "En cada paso de entrenamiento, el modelo buscará predecir las palabras objetivo N+1 (y más allá) utilizando la oración fuente y las palabras objetivo 0 a N.\n",
        "\n",
        "Como tal, el conjunto de datos de entrenamiento generará una tupla `(inputs, targets)`, donde:  \n",
        "\n",
        "- _inputs_ es un diccionario con las claves `encoder_inputs` y `decoder_inputs`.  \n",
        "`encoder_inputs` es la oración fuente vectorizada y `decoder_inputs` es la oración objetivo \"hasta ahora\", es decir, las palabras 0 a N utilizadas para predecir la palabra N+1 (y más allá) en la oración objetivo.  \n",
        "- _target_ es el objetivo es la oración objetivo compensada por un paso: proporciona las siguientes palabras en la oración objetivo: lo que el modelo intentará predecir."
      ],
      "metadata": {
        "id": "5q8WfHTfhcTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "La función `format_dataset` esta diseñada para dar formato a un conjunto de datos\n",
        "que contiene textos en inglés (`eng`) y textos en español (`spa`).\n",
        "Esta función se usa para preparar datos para un modelo de traducción automática.\n",
        "\n",
        "Esto haca esta función:\n",
        "\n",
        "1. 'eng = eng_vectorization(eng)' y 'spa = spa_vectorization(spa)':\n",
        "   Estas líneas aplican la vectorización a los textos en inglés ('eng') y\n",
        "   español ('spa').\n",
        "   'eng_vectorization' y 'spa_vectorization' fueron definidaas anteriormente,\n",
        "   son funciones que toman textos en su forma original y los transforman\n",
        "   utilizando técnicas de vectorización con 'TextVectorization'.\n",
        "\n",
        "2. 'return ({...}, ...)':\n",
        "   La función retorna un diccionario y un tensor.\n",
        "   En el diccionario, se espera que el tensor 'encoder_inputs' contenga los\n",
        "   textos en inglés procesados, y el tensor 'decoder_inputs' contendrá los\n",
        "   textos en español pero truncados por la derecha para su uso como entradas del\n",
        "   decodificador.\n",
        "   Además, el tensor retornado fuera del diccionario contiene los textos en\n",
        "   español pero truncados por la izquierda para su uso como objetivos de salida\n",
        "   del modelo.\n",
        "\"\"\"\n",
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)\n",
        "    spa = spa_vectorization(spa)\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": spa[:, :-1],\n",
        "        },\n",
        "        spa[:, 1:],\n",
        "    )\n"
      ],
      "metadata": {
        "id": "xlgaKqMrQlZv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YWAipxgz_u4Q"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Esta función crea un conjunto de datos en formato apropiado para entrenar un\n",
        "modelo de aprendizaje automático de traducción, con pares de textos en inglés y español.\n",
        "\n",
        "Esta es la explicación paso a paso de lo que hace esta función:\n",
        "\n",
        "1. 'eng_texts, spa_texts = zip(*pairs)':\n",
        "   'pairs' es una lista de pares de textos, donde el primer elemento de cada par\n",
        "   corresponde a un texto en inglés y el segundo a un texto en español.\n",
        "   'zip(*pairs)' desempaqueta estos pares en dos secuencias separadas:\n",
        "   'eng_texts' (textos en inglés) y 'spa_texts' (textos en español).\n",
        "\n",
        "2. 'eng_texts = list(eng_texts)' y 'spa_texts = list(spa_texts)':\n",
        "      Convierte las secuencias de textos en inglés y español de tuplas a listas.\n",
        "\n",
        "3. 'dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))':\n",
        "      Crea un conjunto de datos TensorFlow 'dataset' a partir de las listas de\n",
        "      textos en inglés y español. Usa 'from_tensor_slices' para generar un\n",
        "      dataset a partir de los tensores 'eng_texts' y 'spa_texts'.\n",
        "\n",
        "4. 'dataset = dataset.batch(batch_size)':\n",
        "      Agrupa los elementos del dataset en lotes de tamaño 'batch_size'.\n",
        "\n",
        "5. 'dataset = dataset.map(format_dataset)':\n",
        "      Aplica la función `format_dataset` a cada elemento del dataset.\n",
        "      Esta función 'format_dataset' posiblemente realiza algún tipo de\n",
        "      preprocesamiento o transformación de los datos, como la vectorización de\n",
        "      los textos, ajuste de longitudes, etc.\n",
        "\n",
        "6. 'return dataset.cache().shuffle(2048).prefetch(16)':\n",
        "      Devuelve el dataset con ciertas operaciones encadenadas:\n",
        "   - 'cache()': Almacena en caché los datos en memoria, lo que puede acelerar el\n",
        "      entrenamiento si se repite varias veces.\n",
        "   - 'shuffle(2048)': Mezcla aleatoriamente los elementos del dataset utilizando\n",
        "      un búfer de tamaño 2048 (tamaño del búfer de mezcla).\n",
        "   - 'prefetch(16)': Carga lotes de datos adicionales (16 lotes, en este caso)\n",
        "      en memoria antes de que se soliciten, lo que puede mejorar la velocidad de\n",
        "      entrenamiento al permitir que la GPU o CPU acceda a los datos de forma más eficiente.\n",
        "\"\"\"\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "7EW8nXfiR0fx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos de manera rápida a las formas de las secuencias (tenemos lotes de 64 pares y todas las secuencias tienen 20 pasos):"
      ],
      "metadata": {
        "id": "DD-yhmOBisVl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0ruo3Qle_u4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682abbd9-b2b7-43c1-cb30-8bdfe207ecb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construyendo el modelo\n",
        "1. `TransformerEncoder`\n",
        "2. `PositionalEmbedding`\n",
        "3. `TransformerDecoder`\n",
        "\n",
        "Nuestro `Transformer` _`secuencia a secuencia`_ consta de un `TransformerEncoder` y un `TransformerDecoder` encadenados.   \n",
        "Para que el modelo tenga en cuenta el orden de las palabras, también utilizamos una capa `PositionalEmbedding`.\n",
        "\n",
        "La secuencia fuente se pasará al `TransformerEncoder`, que producirá una nueva representación de la misma. Esta nueva representación luego se pasará al `TransformerDecoder`, junto con la secuencia objetivo hasta el momento (palabras objetivo 0 a N).   \n",
        "\n",
        "Luego, `TransformerDecoder` buscará predecir las siguientes palabras en la secuencia objetivo (N+1 y más).\n",
        "\n",
        "Un detalle clave que hace esto posible es el enmascaramiento causal (consulte el método get_causal_attention_mask() en `TransformerDecoder`).  \n",
        "El `TransformerDecoder` ve las secuencias completas a la vez y, por lo tanto, debemos asegurarnos de que solo use información de los tokens objetivo 0 a N al predecir el token N+1 (de lo contrario, podría usar información del futuro, lo que daría como resultado un modelo que no se puede utilizar en el momento de la inferencia)."
      ],
      "metadata": {
        "id": "OM86ILcYi4YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Esta clase 'TransformerEncoder' representa una capa de un modelo Transformer\n",
        "para la etapa de codificación (encoder).\n",
        "\n",
        "Aquí está la explicación de sus partes:\n",
        "\n",
        "- '__init__': El método '__init__' inicializa los parámetros de la capa.\n",
        "     Recibe como argumentos 'embed_dim', 'dense_dim' y 'num_heads', que\n",
        "    representan la dimensionalidad de los embeddings, la dimensionalidad de las\n",
        "    capas densas y el número de encabezado, respectivamente.\n",
        "\n",
        "    En este método se definen las diferentes capas que componen la capa del encoder:\n",
        "  - 'self.attention': Una capa de atención multi-cabeza ('layers.MultiHeadAttention')\n",
        "     que usa el número de encabezados y la dimensionalidad del embedding para calcular\n",
        "     la atención entre las diferentes partes de la secuencia de entrada.\n",
        "  - 'self.dense_proj': Una secuencia de capas densas ('tf.keras.Sequential')\n",
        "     compuesta por dos capas densas, una con una activación ReLU ('layers.Dense(dense_dim, activation=\"relu\")')\n",
        "     y otra sin activación ('layers.Dense(embed_dim)').\n",
        "  - 'self.layernorm_1' y 'self.layernorm_2': Capas de normalización ('layers.LayerNormalization')\n",
        "     aplicadas después de ciertas operaciones para estabilizar el entrenamiento.\n",
        "  - 'self.supports_masking': Indica que esta capa admite el uso de máscaras durante\n",
        "     el entrenamiento (para ocultar ciertas partes de las secuencias).\n",
        "\n",
        "- 'call': El método 'call' define la lógica de cómo se propaga la entrada a través\n",
        "    de la capa. Toma la entrada `inputs` y una máscara opcional 'mask'.\n",
        "    Realiza los siguientes pasos:\n",
        "  - Si hay una máscara, se prepara una máscara de relleno ('padding_mask') utilizando\n",
        "    la máscara proporcionada.\n",
        "  - Calcula la atención usando la capa de atención multi-cabeza entre la entrada y\n",
        "    ella misma, aplicando la máscara de relleno si está presente.\n",
        "  - Aplica normalización y proyección densa a la salida de la atención.\n",
        "  - Retorna la salida de la segunda capa de normalización.\n",
        "\n",
        "- 'get_config': El método 'get_config' devuelve la configuración de la capa,\n",
        "   incluyendo los valores de 'embed_dim', 'dense_dim' y 'num_heads'.\n",
        "\"\"\"\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = tf.keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "I09r_nrlVjFy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Esta clase en TensorFlow representa una capa de incrustación posicional que se\n",
        "usa comúnmente en modelos de atención o transformadores para incorporar información\n",
        "sobre la posición de las palabras en una secuencia.\n",
        "\n",
        "- '__init__': En el constructor '__init__', se definen dos capas de incrustación\n",
        "   ('Embedding') para tokens y posiciones. Ambas capas tienen como entrada la\n",
        "   dimensión del vocabulario y la longitud de la secuencia, respectivamente, y\n",
        "   tienen la misma dimensión de incrustación (`embed_dim`). Se almacenan también\n",
        "   los parámetros de la secuencia, tamaño de vocabulario y dimensión de incrustación\n",
        "   para su uso posterior.\n",
        "\n",
        "- 'call': En el método 'call', se calcula la incrustación posicional sumando las\n",
        "   incrustaciones de tokens y posiciones. Los tokens se pasan a través de la capa\n",
        "   de incrustación de tokens ('token_embeddings'), y las posiciones se generan usando\n",
        "   'tf.range()' y luego se pasan a través de la capa de incrustación de posiciones\n",
        "   ('position_embeddings'). Estas incrustaciones se suman elemento a elemento.\n",
        "\n",
        "- 'compute_mask': Esta función se utiliza para generar una máscara que indica las\n",
        "   posiciones en las que los tokens son diferentes de cero. Si la entrada es cero,\n",
        "   se devuelve 'None'; de lo contrario, se devuelve una máscara booleana que indica\n",
        "   los valores diferentes de cero.\n",
        "\n",
        "- 'get_config': Devuelve la configuración de la capa, lo que permite reconstruir\n",
        "   la capa con la misma configuración. Retorna un diccionario con la longitud de\n",
        "   secuencia, tamaño del vocabulario y dimensión de incrustación.\n",
        "\"\"\"\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if mask is None:\n",
        "            return None\n",
        "        else:\n",
        "            return tf.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n"
      ],
      "metadata": {
        "id": "WbL23-xCVsWI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Esta clase 'TransformerDecoder' representa una capa del decodificador de un\n",
        "modelo de Transformer.\n",
        "El decodificador en un modelo de Transformer es responsable de generar la salida secuencial,\n",
        "basándose en la información generada por el codificador  y la salida previamente generada.\n",
        "\n",
        "Esta es la explicación del código:\n",
        "\n",
        "- '__init__': En el constructor '__init__', se inicializan varias capas necesarias\n",
        "     para el decodificador. Esto incluye capas de atención ('attention_1' y 'attention_2')\n",
        "     que permiten al decodificador enfocarse en diferentes partes de la entrada y las\n",
        "     incrustaciones (`dense_proj`) que se utilizan para proyectar y transformar las características.\n",
        "\n",
        "- 'call': En el método `call`, se lleva a cabo el cálculo del decodificador.\n",
        "     Se genera una máscara de atención causal (`causal_mask`) que se utiliza para\n",
        "     asegurar que en cada paso de tiempo, las predicciones futuras no se utilicen\n",
        "     para generar la salida actual. Luego, se aplican capas de atención y normalización\n",
        "     a los datos de entrada y a las salidas del codificador, y se realiza una proyección\n",
        "     con la capa densa.\n",
        "\n",
        "- 'get_causal_attention_mask': Este método crea una máscara de atención causal.\n",
        "     Esta máscara se utiliza en la capa de atención para evitar que las posiciones\n",
        "     futuras influyan en las posiciones actuales durante la generación de la secuencia.\n",
        "\n",
        "- 'get_config': Este método devuelve la configuración de la capa. Devuelve un\n",
        "     diccionario con los parámetros del decodificador.\n",
        "\"\"\"\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = tf.keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, None, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, None]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "8PRcNeRCDGCK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, ensamblamos el modelo de un extremo a otro."
      ],
      "metadata": {
        "id": "xqksj8fGm8n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n"
      ],
      "metadata": {
        "id": "eHcc6kmstjxD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZQysrIAT_u4R"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Este código crea un modelo de Transformer para tareas de secuencia a secuencia.\n",
        "Este es el desglose de lo que hace:\n",
        "\n",
        "1. Definición de parámetros:\n",
        "   Se definen los parámetros 'embed_dim', 'latent_dim' y 'num_heads', que representan\n",
        "   la dimensión de incrustación, la dimensión latente y el número de cabezas de atención,\n",
        "   respectivamente.\n",
        "\n",
        "2. Creación del codificador:\n",
        "   Se define el modelo del codificador. Utiliza la capa de entrada 'encoder_inputs'\n",
        "   y se pasa a través de una capa de incrustación posicional ('PositionalEmbedding')\n",
        "   que asigna incrustaciones a las entradas del codificador.\n",
        "\n",
        "   Luego, pasa por la capa del codificador ('TransformerEncoder') para producir\n",
        "   los 'encoder_outputs'. Este modelo del codificador se define utilizando la API\n",
        "   funcional de Keras.\n",
        "\n",
        "3. Creación del decodificador:\n",
        "   Se define el modelo del decodificador. Utiliza las capas de entrada 'decoder_inputs'\n",
        "   y 'encoded_seq_inputs'. Similar al codificador, las entradas del decodificador\n",
        "   pasan a través de una capa de incrustación posicional ('PositionalEmbedding') y\n",
        "   luego por la capa del decodificador ('TransformerDecoder').\n",
        "\n",
        "   Después de eso, se aplica una capa de dropout y se pasa a través de una capa\n",
        "   densa con activación softmax para generar las salidas del decodificador.\n",
        "\n",
        "4. Modelo final del Transformer:\n",
        "   Finalmente, se define el modelo global del Transformer, que toma las entradas\n",
        "   del codificador y del decodificador ('encoder_inputs' y 'decoder_inputs') para\n",
        "   generar las salidas del decodificador.\n",
        "\n",
        "   Este modelo se construye utilizando la API funcional de Keras.\n",
        "\n",
        "\"\"\"\n",
        "# Estaas variables ya fueron definidas anteriormente\n",
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualización de la arquitectura de un modelo de red neuronal\n",
        "Estas lineas de código son útiles para visualizar la arquitectura de un modelo de red neuronal de TensorFlow Keras, mostrando las capas del modelo y cómo están conectadas. El archivo de imagen model_plot.png contendrá el diagrama generado del modelo.\n",
        "Explicación de las siguientes líneas decódigo:\n",
        "\n",
        "```Python\n",
        "    from tensorflow.keras.utils import plot_model\n",
        "```\n",
        "    Importa la función plot_model de la biblioteca tensorflow.keras.utils. Esta función se utiliza para generar un diagrama visual del modelo.\n",
        "\n",
        "```Python\n",
        "    plot_model(transformer, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "```\n",
        "    Genera un diagrama del modelo proporcionado como argumento (transformer en este caso) y lo guarda como una imagen llamada model_plot.png.\n",
        "\n",
        "Los parámetros opcionales `show_shapes=True` y `show_layer_names=True` controlan si se muestran los detalles de las formas de las capas y los nombres de las capas, respectivamente, en el diagrama generado."
      ],
      "metadata": {
        "id": "VbMpuu0yvwcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "# Generar un diagrama del modelo y guardarlo como imagen\n",
        "plot_model(transformer, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "aSjhBpXRs3N6",
        "outputId": "2848523c-603c-4187-d7af-26bde2704f2b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viJb47Dd_u4S"
      },
      "source": [
        "## Entrenando nuestro modelo\n",
        "\n",
        "Usaremos la precisión como una forma rápida de monitorear el progreso del entrenamiento en los datos de validación.\n",
        "Tenga en cuenta que la traducción automática suele utilizar puntuaciones BLEU, así como otras métricas, en lugar de precisión.\n",
        "\n",
        "Aquí solo entrenamos durante 1 época, pero para que el modelo realmente converja debes entrenar durante al menos 30 épocas."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puntuación BLEU (Bilingual Evaluation Understudy)\n",
        "La puntuación BLEU (Bilingual Evaluation Understudy) es una métrica comúnmente utilizada para evaluar la calidad de las traducciones generadas por sistemas de traducción automática. Fue propuesta para proporcionar una medida automatizada de la calidad de las traducciones, en comparación con las evaluaciones manuales que pueden ser costosas y laboriosas de realizar.\n",
        "\n",
        "El objetivo principal de BLEU es cuantificar qué tan cerca está una traducción automática de una referencia o un conjunto de referencias humanas (traducciones de alta calidad realizadas por humanos) para un determinado texto.\n",
        "\n",
        "El proceso de cálculo de la puntuación BLEU implica los siguientes pasos:\n",
        "\n",
        "1. **N-gram overlap:** Compara la similitud entre los n-gramas (secuencias de n palabras) en la traducción generada y las referencias humanas. Generalmente se utilizan n-gramas de longitud 1 a 4.\n",
        "\n",
        "2. **Precision:** Evalúa qué porcentaje de los n-gramas en la traducción automática coinciden con los presentes en las referencias. Cuanto mayor sea la coincidencia, mayor será la puntuación de precisión.\n",
        "\n",
        "3. **Brevity Penalty:** Penaliza las traducciones que son más cortas en comparación con las referencias, ya que una traducción muy corta podría tener una puntuación alta en precisión pero podría no ser una traducción adecuada.\n",
        "\n",
        "La puntuación BLEU se calcula como un valor entre 0 y 1, donde 1 indica una coincidencia perfecta con las referencias humanas. Sin embargo, es importante tener en cuenta que la puntuación BLEU no es perfecta y puede no capturar todos los aspectos de la calidad de la traducción, ya que se centra principalmente en la similitud de los n-gramas y no en la comprensión semántica o la coherencia global del texto traducido."
      ],
      "metadata": {
        "id": "Qtg2aPZDVsGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## n-gramas\n",
        "Los \"n-gramas\" son secuencias de palabras consecutivas tomadas de un texto, donde \"n\" representa el número de palabras en cada secuencia. Estos n-gramas son utilizados en procesamiento de lenguaje natural y análisis de texto para capturar la estructura y las características del lenguaje.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "- **Unigrama (1-grama):** Un unigrama consiste en una sola palabra. Por ejemplo, en la oración \"El perro corre\", los unigramas serían: \"El\", \"perro\", \"corre\".\n",
        "\n",
        "- **Bigrama (2-grama):** Un bigrama consiste en secuencias de dos palabras consecutivas. Siguiendo el ejemplo anterior, los bigramas serían: \"El perro\", \"perro corre\".\n",
        "\n",
        "- **Trigrama (3-grama):** Un trigrama consta de secuencias de tres palabras consecutivas. En la misma oración, los trigramas serían: \"El perro corre\".\n",
        "\n",
        "- **Cuatrigrama (4-grama):** Un cuatrigrama se compone de secuencias de cuatro palabras consecutivas. Para la oración dada, solo hay un cuatrigrama: \"El perro corre\".\n",
        "\n",
        "Estos n-gramas se utilizan en diversas aplicaciones de procesamiento de lenguaje natural, como modelos de lenguaje, traducción automática, extracción de características en análisis de texto, entre otros. La elección del valor de \"n\" determina el nivel de detalle o granularidad de las secuencias de palabras utilizadas para el análisis del texto."
      ],
      "metadata": {
        "id": "ei13HLegV2iv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuoUjJVT_u4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "088cc092-a09f-4f29-b7ef-0d830ed14c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " positional_embedding (Posi  (None, None, 256)            3845120   ['encoder_inputs[0][0]']      \n",
            " tionalEmbedding)                                                                                 \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, None)]               0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " transformer_encoder (Trans  (None, None, 256)            3155456   ['positional_embedding[0][0]']\n",
            " formerEncoder)                                                                                   \n",
            "                                                                                                  \n",
            " model_1 (Functional)        (None, None, 15000)          1295964   ['decoder_inputs[0][0]',      \n",
            "                                                          0          'transformer_encoder[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19960216 (76.14 MB)\n",
            "Trainable params: 19960216 (76.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/40\n",
            "1302/1302 [==============================] - 107s 78ms/step - loss: 1.3085 - accuracy: 0.8088 - val_loss: 0.9882 - val_accuracy: 0.8460\n",
            "Epoch 2/40\n",
            " 265/1302 [=====>........................] - ETA: 1:07 - loss: 1.0224 - accuracy: 0.8421"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "epochs = 40  # Esto debería ser al menos 30 para la convergencia.\n",
        "            # El entrenamiento con 30 epochs lleva aprox. 50 minutos\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "# CUIDADO AQUI ESTÁ COMENTADO PARA NO ENTRENAR DE NUEVO\n",
        "# Descometar la siguiente linea para Entrenar la Red\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb5MwkyrRYEe",
        "outputId": "83c1ceee-0fbb-4a6d-c87b-163adb8ffa7c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Camino y nombre del Traslator entrenado\n",
        "fileTraslator = 'gdrive/My Drive/Colab Notebooks/Curso NN/Traslator'"
      ],
      "metadata": {
        "id": "imNvaK2yRIED"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Aquí guardamos el Transformer entrenado\n",
        "Si ya lo tenemos entrenado, entonces no hay que guardarlo, pues perderíamos todo\n",
        "\"\"\"\n",
        "transformer.save(fileTraslator)"
      ],
      "metadata": {
        "id": "arBi371fR7IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Aquí lo cargamos al Transformer\n",
        "\"\"\"\n",
        "# Cargar el modelo entrenado\n",
        "transformer = load_model(fileTraslator)"
      ],
      "metadata": {
        "id": "6CfBdARURTTh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPPHkKNb_u4S"
      },
      "source": [
        "## Decodificar oraciones de prueba\n",
        "\n",
        "Finalmente, demostremos cómo traducir oraciones nuevas en inglés.  \n",
        "\n",
        "Simplemente introducimos en el modelo la frase en inglés vectorizada, así como el token de destino `\"[start]\"`, luego generamos repetidamente el siguiente token, hasta que llegamos al token `\"[end]\"`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "R-MISesYFRVN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print('Inglés  : ', input_sentence)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print('Español :', translated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2hTTLGZWfc0",
        "outputId": "0cf72d42-eacc-453c-f8ca-d5c940ad4eae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inglés  :  He saw a pretty girl.\n",
            "Español : [start] los se [UNK] una ningún estudiando [end]\n",
            "Inglés  :  He plays soccer.\n",
            "Español : [start] los si traté [end]\n",
            "Inglés  :  Let's hope Tom didn't do what you think he did.\n",
            "Español : [start] [UNK] de tom lo que siempre bien voy [end]\n",
            "Inglés  :  Please come downstairs.\n",
            "Español : [start] yo [UNK] mi al tenemos [end]\n",
            "Inglés  :  The customer agrees.\n",
            "Español : [start] el carácter pelando [end]\n",
            "Inglés  :  I always rest for an hour after dinner.\n",
            "Español : [start] jugar viven por sabe hiciste de misma [end]\n",
            "Inglés  :  You have only to answer the first question.\n",
            "Español : [start] creo que del hace una sea [end]\n",
            "Inglés  :  I'll never forget the sound the crash made.\n",
            "Español : [start] por todos [UNK] que esa la tuve mi máquina [end]\n",
            "Inglés  :  I was foolish enough to believe him.\n",
            "Español : [start] si retrasó allí cuando al seguro [end]\n",
            "Inglés  :  Five times five is twenty-five.\n",
            "Español : [start] no son hablaba [UNK] [end]\n",
            "Inglés  :  I hope I can go to Australia one day.\n",
            "Español : [start] yo miedo puedo era en esta quedó [end]\n",
            "Inglés  :  She always has time in the afternoon.\n",
            "Español : [start] le hay estación tiempo en el libros [end]\n",
            "Inglés  :  Look, I know you're busy.\n",
            "Español : [start] haber sé lo padre [end]\n",
            "Inglés  :  I have no idea what you mean.\n",
            "Español : [start] fue una contigo en el hombres [end]\n",
            "Inglés  :  Write a short essay.\n",
            "Español : [start] la suelo de su cara padres [end]\n",
            "Inglés  :  This knife isn't very sharp.\n",
            "Español : [start] me tener me [UNK] al quedaré [end]\n",
            "Inglés  :  Most of the students here go to school on bike.\n",
            "Español : [start] el leche él siquiera todas de su [UNK] al demasiado [end]\n",
            "Inglés  :  What did I miss?\n",
            "Español : [start] qué muy me médico mi turno [end]\n",
            "Inglés  :  He kept his promise.\n",
            "Español : [start] los más la de Él cuando en cambiar [end]\n",
            "Inglés  :  I like the heat.\n",
            "Español : [start] me debes y das [end]\n",
            "Inglés  :  Tom was my closest friend.\n",
            "Español : [start] tom si con ganas dejará [end]\n",
            "Inglés  :  I'm learning English.\n",
            "Español : [start] no morir [end]\n",
            "Inglés  :  It's pretty cool.\n",
            "Español : [start] es la bella trata [end]\n",
            "Inglés  :  I'd be unhappy, but I wouldn't kill myself.\n",
            "Español : [start] trabajo hijos el tv mesa y niño me gusta [end]\n",
            "Inglés  :  You've never been to Paris, have you?\n",
            "Español : [start] horas nunca en lo más hijo que creo [end]\n",
            "Inglés  :  Tom put the envelope on the table.\n",
            "Español : [start] tom al ciudad en la prefiero [end]\n",
            "Inglés  :  Mary likes to party.\n",
            "Español : [start] va es blanco para [UNK] [end]\n",
            "Inglés  :  Do you like living here?\n",
            "Español : [start] te gusta 10 [end]\n",
            "Inglés  :  I ran around the field.\n",
            "Español : [start] me mucho estas al [UNK] [end]\n",
            "Inglés  :  Just a minute.\n",
            "Español : [start] gustaría tiene un película [end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLKpQg5h_u4T"
      },
      "source": [
        "Después de 30 épocas, obtenemos resultados como:\n",
        "\n",
        "> She handed him the money.\n",
        "> [start] ella le pasó el dinero [end]\n",
        "\n",
        "> Tom has never heard Mary sing.\n",
        "> [start] tom nunca ha oído cantar a mary [end]\n",
        "\n",
        "> Perhaps she will come tomorrow.\n",
        "> [start] tal vez ella vendrá mañana [end]\n",
        "\n",
        "> I love to write.\n",
        "> [start] me encanta escribir [end]\n",
        "\n",
        "> His French is improving little by little.\n",
        "> [start] su francés va a [UNK] sólo un poco [end]\n",
        "\n",
        "> My hotel told me to call you.\n",
        "> [start] mi hotel me dijo que te [UNK] [end]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = \"Hello, thank you for to be in these lessons.\"\n",
        "translated_sentence = decode_sequence(input_sentence)\n",
        "print(\"Frase traducida:\", translated_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocQ0Cl_yHOMb",
        "outputId": "b55e3c3d-df9b-40c7-dd69-6ee31b3b5d5c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase traducida: [start] a y levantó en que te común año a la levantó [end]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}